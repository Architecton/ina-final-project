C:\Users\Grega\AppData\Local\Programs\Python\Python38\pythonw.exe C:/Users/Grega/PycharmProjects/ina-final-project/src/deep_learning.py
--------------------------------
Reading dataset from C:\Users\Grega\PycharmProjects\ina-final-project\data\deep_learning\final\chicago_regional_transformed
Finished reading data.
Setting up graph.
Finished setting up graph.
Setting up examples.
Finished setting up examples.
Dataset properties:
Mode: train
Number of vertices: 1467
Number of static edges: 480
Number of temporal edges: 480
Number of examples/datapoints: 648
--------------------------------
GAT(
  (attn): ModuleList(
    (0): GraphAttention(
      (fcs): ModuleList(
        (0): Linear(in_features=1467, out_features=64, bias=True)
      )
      (a): ModuleList(
        (0): Linear(in_features=128, out_features=1, bias=True)
      )
      (dropout): Dropout(p=0, inplace=False)
      (softmax): Softmax(dim=0)
      (leakyrelu): LeakyReLU(negative_slope=0.01)
    )
    (1): GraphAttention(
      (fcs): ModuleList(
        (0): Linear(in_features=64, out_features=1, bias=True)
      )
      (a): ModuleList(
        (0): Linear(in_features=2, out_features=1, bias=True)
      )
      (dropout): Dropout(p=0, inplace=False)
      (softmax): Softmax(dim=0)
      (leakyrelu): LeakyReLU(negative_slope=0.01)
    )
  )
  (bns): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0, inplace=False)
  (elu): ELU(alpha=1.0)
)
--------------------------------
Computing ROC-AUC score for the training dataset before training.
Setting up a new session...
ROC-AUC score: 0.4994
--------------------------------
--------------------------------
Training.
Finished training.
--------------------------------
--------------------------------
Saving model at C:\Users\Grega\PycharmProjects\ina-final-project\trained_models\graphsage_agg_class_MaxPoolAggregator_hidden_dims_64_num_samples_-1_batch_size_32_epochs_20_lr_0.0005_weight_decay_0.0005_duplicate_False_repeat_True.pth
Finished saving model.
--------------------------------
--------------------------------
Computing ROC-AUC score for the training dataset after training.
ROC-AUC score: 0.9828
--------------------------------
Threshold: -0.0737, accuracy: 0.8981
Classification report
               precision    recall  f1-score   support

         0.0       0.91      0.89      0.90       324
         1.0       0.89      0.91      0.90       324

    accuracy                           0.90       648
   macro avg       0.90      0.90      0.90       648
weighted avg       0.90      0.90      0.90       648

--------------------------------
Reading dataset from C:\Users\Grega\PycharmProjects\ina-final-project\data\deep_learning\final\chicago_regional_transformed
Finished reading data.
Setting up graph.
Finished setting up graph.
Setting up examples.
Finished setting up examples.
Dataset properties:
Mode: val
Number of vertices: 1467
Number of static edges: 804
Number of temporal edges: 804
Number of examples/datapoints: 338
--------------------------------
--------------------------------
Computing ROC-AUC score for the validation dataset after training.
Classification report
               precision    recall  f1-score   support

         0.0       0.49      0.46      0.48       169
         1.0       0.49      0.53      0.51       169

    accuracy                           0.49       338
   macro avg       0.49      0.49      0.49       338
weighted avg       0.49      0.49      0.49       338

Finished validating.
--------------------------------
--------------------------------
Reading dataset from C:\Users\Grega\PycharmProjects\ina-final-project\data\deep_learning\final\chicago_regional_transformed
Finished reading data.
Setting up graph.
Finished setting up graph.
Setting up examples.
Finished setting up examples.
Dataset properties:
Mode: test
Number of vertices: 1467
Number of static edges: 973
Number of temporal edges: 973
Number of examples/datapoints: 648
--------------------------------
--------------------------------
Computing ROC-AUC score for the test dataset after training.
Classification report
               precision    recall  f1-score   support

         0.0       0.50      0.44      0.47       324
         1.0       0.50      0.57      0.53       324

    accuracy                           0.50       648
   macro avg       0.50      0.50      0.50       648
weighted avg       0.50      0.50      0.50       648

Finished testing.
--------------------------------

Process finished with exit code 0
