C:\Users\Grega\AppData\Local\Programs\Python\Python38\pythonw.exe C:/Users/Grega/PycharmProjects/ina-final-project/src/deep_learning.py
--------------------------------
Reading dataset from C:\Users\Grega\PycharmProjects\ina-final-project\data\deep_learning\final\bible_transformed
Finished reading data.
Setting up graph.
Finished setting up graph.
Setting up examples.
Finished setting up examples.
Dataset properties:
Mode: train
Number of vertices: 1773
Number of static edges: 3378
Number of temporal edges: 3378
Number of examples/datapoints: 4566
--------------------------------
GAT(
  (attn): ModuleList(
    (0): GraphAttention(
      (fcs): ModuleList(
        (0): Linear(in_features=1773, out_features=64, bias=True)
      )
      (a): ModuleList(
        (0): Linear(in_features=128, out_features=1, bias=True)
      )
      (dropout): Dropout(p=0, inplace=False)
      (softmax): Softmax(dim=0)
      (leakyrelu): LeakyReLU(negative_slope=0.01)
    )
    (1): GraphAttention(
      (fcs): ModuleList(
        (0): Linear(in_features=64, out_features=1, bias=True)
      )
      (a): ModuleList(
        (0): Linear(in_features=2, out_features=1, bias=True)
      )
      (dropout): Dropout(p=0, inplace=False)
      (softmax): Softmax(dim=0)
      (leakyrelu): LeakyReLU(negative_slope=0.01)
    )
  )
  (bns): ModuleList(
    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0, inplace=False)
  (elu): ELU(alpha=1.0)
)
--------------------------------
Computing ROC-AUC score for the training dataset before training.
ROC-AUC score: 0.5072
--------------------------------
Setting up a new session...
--------------------------------
Training.
Finished training.
--------------------------------
--------------------------------
Saving model at C:\Users\Grega\PycharmProjects\ina-final-project\trained_models\graphsage_agg_class_MaxPoolAggregator_hidden_dims_64_num_samples_-1_batch_size_32_epochs_20_lr_0.0005_weight_decay_0.0005_duplicate_False_repeat_True.pth
Finished saving model.
--------------------------------
--------------------------------
Computing ROC-AUC score for the training dataset after training.
ROC-AUC score: 0.8242
--------------------------------
Threshold: 0.0883, accuracy: 0.7144
Classification report
               precision    recall  f1-score   support

         0.0       0.71      0.72      0.72      2283
         1.0       0.72      0.71      0.71      2283

    accuracy                           0.71      4566
   macro avg       0.71      0.71      0.71      4566
weighted avg       0.71      0.71      0.71      4566

--------------------------------
Reading dataset from C:\Users\Grega\PycharmProjects\ina-final-project\data\deep_learning\final\bible_transformed
Finished reading data.
Setting up graph.
Finished setting up graph.
Setting up examples.
Finished setting up examples.
Dataset properties:
Mode: val
Number of vertices: 1773
Number of static edges: 5661
Number of temporal edges: 5661
Number of examples/datapoints: 2374
--------------------------------
--------------------------------
Computing ROC-AUC score for the validation dataset after training.
Classification report
               precision    recall  f1-score   support

         0.0       0.46      0.48      0.47      1187
         1.0       0.46      0.44      0.45      1187

    accuracy                           0.46      2374
   macro avg       0.46      0.46      0.46      2374
weighted avg       0.46      0.46      0.46      2374

Finished validating.
--------------------------------
--------------------------------
Reading dataset from C:\Users\Grega\PycharmProjects\ina-final-project\data\deep_learning\final\bible_transformed
Finished reading data.
Setting up graph.
Finished setting up graph.
Setting up examples.
Finished setting up examples.
Dataset properties:
Mode: test
Number of vertices: 1773
Number of static edges: 6848
Number of temporal edges: 6848
Number of examples/datapoints: 4566
--------------------------------
--------------------------------
Computing ROC-AUC score for the test dataset after training.
Classification report
               precision    recall  f1-score   support

         0.0       0.78      0.38      0.52      2283
         1.0       0.59      0.89      0.71      2283

    accuracy                           0.64      4566
   macro avg       0.69      0.64      0.61      4566
weighted avg       0.69      0.64      0.61      4566

Finished testing.
--------------------------------

Process finished with exit code 0